{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:left\" width=\"70%\" src=\"pics/escudo_COLOR_1L_DCHA.png\">\n",
    "<img style=\"float:right\" width=\"15%\" src=\"pics/PythonLogo.svg\">\n",
    "<br style=\"clear:both;\">\n",
    "\n",
    "# Minería de datos\n",
    "\n",
    "<h2 style=\"display: inline-block; padding: 4mm; padding-left: 2em; background-color: navy; line-height: 1.3em; color: white; border-radius: 10px;\">Scikit-Learn. Parte 1</h2>\n",
    "\n",
    "## Docentes\n",
    "\n",
    " - José Francisco Diez Pastor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"index\"></a>\n",
    "## Tabla de contenidos del notebook\n",
    "\n",
    "1. [Introducción a Scikit-Learn](#intro)\n",
    "    - [Cargar Datasets](#cargar)\n",
    "    - [Entrenando y prediciendo](#entrena_predice)\n",
    "    - [Persistencia. Guardando modelos para usarlos más tarde](#persistencia)\n",
    "2. [Aprendizaje Supervisado](#supervisado)\n",
    "3. [Evaluación de clasificadores y regresores](#evaluacion)\n",
    "    - [Formas de hacer la evaluación](#formas)\n",
    "    - [Medidas de rendimiento](#medidas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo lo módulos necesarios para utilizar *widgets* de Jupyter Notebook. Necesarios para proporcionar interactividad al notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a Scikit-Learn <a id=\"intro\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "Scikit-Learn o Sklearn es la librería básica de minería de datos en Python.\n",
    "\n",
    "Scikit-Learn es una librería que implementa multitud de algoritmos de minería de datos, preprocesamiento, validación de métodos y visualización.\n",
    "\n",
    "En general, un problema de aprendizaje considera un conjunto de ejemplos (conjunto de entrenamiento) y a partir de estos trata de predecir propiedades de nuevos ejemplos nunca vistos.\n",
    "\n",
    "Se pueden separar los problemas de aprendizaje en dos grandes categorías:\n",
    "- Aprendizaje Supervisado. En el que los datos tienen un atributo especial que se quiere predecir.\n",
    "    - Clasificación: Los ejemplos pertenecen a un conjunto de dos o más clases. Y queremos aprender a clasificar nuevos ejemplos a partir de los ejemplos del conjunto de entrenamiento. En clasificación tenemos un conjunto discreto y finito de clases.\n",
    "    - Regresión: El atributo especial o salida que se quiere predecir puede tomar un conjunto continuo de valores.\n",
    "\n",
    "\n",
    "- Aprendizaje no supervisado. En este caso el conjunto de entrenamiento no tiene un atributo especial o clase que queremos predecir (o si lo tiene lo ignoramos). El objetivo de este tipo de problemas es encontrar grupos de ejemplos con características similares (**clustering**), proyectar los datos en un espacio de 2 ó 3 dimensiones para visualizarlo (**proyeciones**) u otro tipo de tareas para las que no se usa la clase.    \n",
    "\n",
    "\n",
    "\n",
    "#### Entrenamiento y Test\n",
    "\n",
    "\n",
    "Es habitual que para evaluar un algoritmo se dividan los datos entre entrenamiento y test. El primero se usa para que el algoritmo aprenda las propiedades de los datos y el segundo para evaluar las propiedades aprendidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar Datasets <a id=\"cargar\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "Scikit-learn viene con un conjunto de datasets, formado por datasets como *iris* o *digit* que son algunos de los datasets más usados para la enseñanza o para evaluar el desempeño de nuevos algoritmos.\n",
    "\n",
    "Todos los datasets se encuentran en el módulo **sklearn.datasets**. Podemos ver una descripción de ellos en http://scikit-learn.org/stable/datasets/\n",
    "\n",
    "\n",
    "Un dataset en sklearn es un objeto similar a un diccionario que contiene los siguientes campos:\n",
    "- data. Un array de tamaño número de ejemplos $\\times$ número de atributos.\n",
    "- target. En el caso de problemas supervisados contendrá la variable objetivo o clase.\n",
    "- feature_names. Contiene los nombres de los atributos.\n",
    "- target_names. En el caso de problemas supervisados contiene el nombre de las clases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# El dataset iris\n",
    "iris = datasets.load_iris()\n",
    "print(iris.data[:10]) # muestro las 10 primeras fílas y columnas\n",
    "print(iris.target[:10]) # las 10 primeras clases (sus índices)\n",
    "print(iris.feature_names)\n",
    "print(iris.target_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A parte de los propios datos que incluyen de ejemplo, se permite cargar cualquier tipo de array de NumPy, matrices de Scipy o DataFrames de Pandas.\n",
    "\n",
    "### Creando nuestros propios datasets\n",
    "\n",
    "Para crear nuestro propio dataset solo necesitamos **data** y **target**.\n",
    "\n",
    "Data ($X$ en notación formal) debe ser una matriz de (número de ejemplos $\\times$ número de atributos) y target ($Y$ en notación formal) es una matriz o lista de tamaño igual a número de ejemplos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)   sepal width (cm)  petal length (cm)   petal width (cm)  \\\n",
       "0                5.1                3.5                1.4                0.2   \n",
       "1                4.9                3.0                1.4                0.2   \n",
       "2                4.7                3.2                1.3                0.2   \n",
       "3                4.6                3.1                1.5                0.2   \n",
       "4                5.0                3.6                1.4                0.2   \n",
       "\n",
       "         Class  \n",
       "0  Iris-setosa  \n",
       "1  Iris-setosa  \n",
       "2  Iris-setosa  \n",
       "3  Iris-setosa  \n",
       "4  Iris-setosa  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('iris.csv')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos dividir el dataset en $X$ e $Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminando la clase (target) nos quedamos solo con los datos de los atributos\n",
    "train_data = df.drop([\"Class\"], axis=1)\n",
    "\n",
    "# Solo queremos los datos, no nos hace falta el nombre de las columnas o los índices\n",
    "train_data = train_data.values\n",
    "\n",
    "train_data[:10] # muestro los 10 primeros por pantalla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecciono target (que en esta dataset se llama Class)\n",
    "target_data = df[\"Class\"].values\n",
    "target_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando y prediciendo <a id=\"entrena_predice\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "El uso básico de un clasificador en Scikit-learn consiste en:\n",
    "- Entrenar un clasificador.\n",
    "- Usar el clasificador para predecir nuevas instancias.\n",
    "\n",
    "A menudo el algoritmo elegido tendrá parámetros que tendremos que elegir y que en apartados posteriores veremos como se pueden ajustar.\n",
    "\n",
    "\n",
    "En el caso de una aplicación en producción, se realizaría el entrenamiento (que puede ser una tarea costosa), se guardaría el clasificador (se serializaría) y luego se recupera el clasificador y se despliega en un servidor o aplicación de cualquier tipo\n",
    "- Usar persistencia para guardar y recuperar un clasificador guardado.\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Scikit-learn todos los modelos tanto supervisados como no supervisados se entrenan con el método **fit** \n",
    "- En modelos supervisados recibe atributos ($X_{train}$) y clase ($Y_{train}$)\n",
    "- En modelos no supervisados recibe solo los atributos ($X_{train}$)\n",
    "\n",
    "Se hacen predicciones con el método **predict** que recibe un array de 2 dimensiones con tantas instancias como se quiera predecir ($X_{test}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "# X = train_data\n",
    "# y = target_data\n",
    "# Los datos del iris cargados anteriormente\n",
    "forest = forest.fit(train_data, target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Haciendo la predicción\n",
    "prediccion = forest.predict([[4.4, 2.9, 1.4, 0.2]])\n",
    "prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atentos a que no recibe una instancia, sino que recibe una lista de instancias, aunque en este caso tenía solo un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Observa que se le pasa en realidad un array 2D\n",
    "# A predict se le pasa un array de instancias, \n",
    "# aunque solo queramos predecir una\n",
    "np.array([[4.4, 2.9, 1.4, 0.2]]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden predecir $N$ ejemplos de una sola operación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.predict([[4.4, 2.9, 1.4, 0.2],\n",
    "                [7.,3.2,  4.7,  1.4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistencia. Guardando modelos para usarlos más tarde <a id=\"persistencia\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "En el caso de una aplicación en producción. Después de entrenar un modelo es recomendable guardarlo para un futuro, para no tener que reentrenarlo cada vez que se quiera usar.\n",
    "\n",
    "Es posible serializar y deserializar modelos usando la librería por defecto de persistencia de Python: Pickle\n",
    "\n",
    "- Con **dump** se guarda el objeto que queramos en un determinado fichero.\n",
    "\n",
    "- Con **load** se recupera un objeto desde un fichero y se almacena en una variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # serializar y deserializar\n",
    "\n",
    "# Un modelo entrenado con los parámetros óptimos que hayamos determinado\n",
    "forestDefinitivo = forest.fit(train_data, target_data)\n",
    "\n",
    "filename = 'randomForest.sav'\n",
    "#guardamos\n",
    "pickle.dump(forestDefinitivo, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente solo tendremos que cargar el clasificador en nuestra aplicación (Una sola vez, al cargar el programa).\n",
    "Lo cargamos una vez al iniciar el programa y lo usamos siempre que queramos.\n",
    "\n",
    "\n",
    "La magic de Jupyter ``%%time`` sirve para saber el tiempo que tarda en ejecutarse una celda. Vemos que cargar un modelo es mucho más rápido que entrenarlo nuevamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cuando arranca la aplicación se carga\n",
    "# en lugar de re-entrenar recuperamos un modelo guardado en milisegundo\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente la aplicación le pasaría instancias al clasificador y este los clasificaría sin problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict([[4.4, 2.9, 1.4, 0.2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consideraciones\n",
    "\n",
    "Scikit learn proporciona una alternativa a pickle que es mucho más eficiente para trabajar con objetos que contienen una gran cantidad de arrays de NumPy.\n",
    "\n",
    "```Python\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(clf, 'filename.pkl') \n",
    "\n",
    "... \n",
    "clf = joblib.load('filename.pkl') \n",
    "```\n",
    "\n",
    "Nunca se debería cargar modelos de una fuente no segura, ya que el modelo podría venir con código malicioso incluido.\n",
    "\n",
    "Aunque se pueden cargar modelos de una versión en otra, puede ocurrir que modelos de versiones diferentes tengan un comportamiento diferente. Así que es buena idea serializar el modelo incluyendo en algún sitio metadatos sobre el número de versión, como por ejemplo en el nombre del fichero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# Un modelo entrenado con los parámetros óptimos y listo para usar\n",
    "forestDefinitivo = forest.fit(train_data, target_data)\n",
    "\n",
    "filename = 'randomForest.sav'\n",
    "#guardamos\n",
    "joblib.dump(forestDefinitivo,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = joblib.load(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tarea 1: Busca en https://scikit-learn.org/stable/datasets/ algún conjunto de datos de clasificación\n",
    "que sea grande. Pero no tan grande como para tardar toda la clase en hacer el ejercicio.\n",
    "\n",
    "Usalo para entrenar un sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "Serialízalo y deserializalo primero con Pickle y luego con joblib.\n",
    "\n",
    "Como el KNeighborsClassifier (k Vecinos más cercanos) almacena todo el conjunto de datos\n",
    "debería notarse la diferencia de usar un tipo u otro de serialización.\n",
    "\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje Supervisado <a id=\"supervisado\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "\n",
    "El aprendizaje supervisado consiste en aprender la relación entre dos arrays de datos:\n",
    "- Los datos observados ($X$), los atributos que describen un determinado individuo o fenómeno.\n",
    "- Los datos que tratamos de predecir ($y$), el *target* o etiqueta. Que generalmente es un array de una dimensión de tamaño igual a número de ejemplos.\n",
    "\n",
    "Todos los algoritmos de aprendizaje supervisado implementan un método **fit(X,y)** que entrena el modelo y un método **predict(X)** que dado un nuevo conjunto de obserbaciones $X$ devuelve precicciones de sus posibles valores $y$.\n",
    "\n",
    "En clasificación la $y$ debe de ser un conjunto finito de etiquetas.\n",
    " - En el caso de Sklearn las etiquetas en clasificación pueden ser enteros o strings.\n",
    "En regresión la $y$ es un conjunto continuo de valores, generalmente floats o doubles.\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frontera de decisión \n",
    "\n",
    "En un problema de clasificación, la frontera de decisión es una hipersuperficie (una superficie es en 3 dimensiones, una hipersuperficie es en $N$ dimensiones) que divide los datos en varios conjuntos, cada conjunto formado por los ejemplos predichos para cada una de las clases.\n",
    "\n",
    "El clasificador va a clasificar los ejemplos como pertenecientes a una de las clases, aquellos casos dudosos estaran pegados a la frontera de decisión.\n",
    "\n",
    "Si la frontera de decisión es un hiperplano, entonces decimos el clasificador es lineal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def visualizar_clasificador(model, X, y, ax=None, cmap='rainbow'):\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Muestra las instancias del conjunto de entrenamiento, sus dos primeras dimensiones.\n",
    "    # scatter sirve para dibujar puntos. c es el color y s el tamaño (size)\n",
    "    # el color se determina de acuerdo a un colormap (mapa de color)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=cmap,\n",
    "               clim=(y.min(), y.max()), zorder=3)\n",
    "    \n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # construye el modelo (ej árbol de decisión)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # crea un conjunto de datos artificial uniformemente distribuido en rejilla\n",
    "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                         np.linspace(*ylim, num=200))\n",
    "    # predice las clases del conjunto de datos artificial\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    # Utiliza los valores y clase del conjunto artificial en rejilla\n",
    "    # para crear un diagrama de contornos\n",
    "    n_classes = len(np.unique(y))\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap=cmap,\n",
    "                           zorder=1)\n",
    "\n",
    "    ax.set(xlim=xlim, ylim=ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_blobs permite crear nubes de puntos de forma esférica\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "'''\n",
    "Creando datos de prueba para los ejemplos\n",
    "Crea 2 nubes de puntos, de 300 puntos en total\n",
    "Las nubes están dispersas con una desviación de 0.75 (ese número concentra o expande los puntos)\n",
    "'''\n",
    "X, y = make_blobs(n_samples=300, centers=2,\n",
    "                  random_state=0, cluster_std=0.8)\n",
    "\n",
    "print(\"Dimensiones de X\",X.shape)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un ejemplo de clasificador lineal: Regresión Logística\n",
    "\n",
    "Regresión Logistica es un modelo lineal, lo que significa que no será capaz de funcionar correctamente en aquellos casos en los que la frontera de decisión entre las clases no sea lineal.\n",
    "\n",
    "A grandes rasgos, el método lo que hace es encontrar un hiperplano que separa las dos clases.\n",
    "\n",
    "El hiperplano que separa las clases se puede definir con la fórmula de la recta o el plano pero extrapolada a $N$ dimensiones.\n",
    "\n",
    "\n",
    "$h_\\beta(X) = \\beta_1 \\times X_1 + \\beta_2 \\times X_2 \\ldots \\beta_n \\times X_n$\n",
    "\n",
    "\n",
    "Probabilidad de que X pertenezca a la clase 1 = $ \\frac{1}{1+ \\text{exp} (h_\\beta(X))} $\n",
    "\n",
    "\n",
    "Probabilidad de que X pertenezca a la clase 0 = $ 1 - \\frac{1}{1+ \\text{exp} (h_\\beta(X))} $\n",
    "\n",
    "\n",
    "Los $\\beta$ optimos se encuentran en el proceso de aprendizaje con un algoritmo de optimización como lo puede ser el descenso del gradiente. Es la versión de clasificación del algoritmo de regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "visualizar_clasificador(lr, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un ejemplo de clasificador no lineal: Vecinos más cercanos\n",
    "\n",
    "El algoritmo de vecinos más cercanos es un ejemplo de aprendizaje basado en instancias, no es un algoritmo que aprenda a generalizar. No construye un modelo, sino que simplemente almacena las instancias del conjunto de entrenamiento.\n",
    "\n",
    "La predicción se realiza por votación simple de los vecinos más cercanos, se asigna la clase más representada entre los vecinos más cercanos de un determinado ejemplo a predecir.\n",
    "\n",
    "Este algoritmo depende del parámetro $k$ (número de vecinos), el valor óptimo de este parámetro es altamente dependiente de cada conjunto de datos.\n",
    "\n",
    "Aunque por lo general a mayor es el valor de $k$ más suave es la frontera de decisión y menos susceptible es al ruido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def plot_knn(k=3):\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    visualizar_clasificador(knn, X, y)\n",
    "\n",
    "\n",
    "interact(plot_knn, k=(1,35,2)); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tarea 2:\n",
    "\n",
    "Piensa en los algoritmos de clasificación del temario a ver si hay alguno que tenga \n",
    "fronteras de decisión con una forma rectilínea, es decir, que divida los datos con cortes\n",
    "perpendiculares a los ejes.\n",
    "\n",
    "Usa los ejemplos anteriores para visualizar el resultados\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un ejemplo de algoritmos de regresión:  Regresión Lineal\n",
    "\n",
    "Regresión lineal es el punto de partida para regresión, es el primer algoritmo que debemos probar.\n",
    "\n",
    "Es un método rápido y fácil de interpretar.\n",
    "\n",
    "Aunque tiene la limitación de que no puede ajustarse correctamente cuando la relación entre los atributos y la variable a predecir no es lineal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# https://github.com/justmarkham/DAT3\n",
    "# Cargar los datos como un dataframe (desde internet)\n",
    "data = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este conjunto de datos se tiene como atributos la cantidad gastada en publicidad en cada uno de los distintos tipos de medios de comunicación.\n",
    "\n",
    "Y la clase son las ventas en millones de dolares del producto anunciado (sales).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtengo los nombres de las columnas del dataframe\n",
    "atts = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización entre los atributos y el valor a predecir\n",
    "fig, axs = plt.subplots(1, 3, sharey=True)\n",
    "data.plot(kind='scatter', x=atts[0], y=atts[3], ax=axs[0], figsize=(16, 8))\n",
    "data.plot(kind='scatter', x=atts[1], y=atts[3], ax=axs[1])\n",
    "data.plot(kind='scatter', x=atts[2], y=atts[3], ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos interesa por una parte ser capaces de predecir el efecto de nuestra inversión (que ventas podriamos tener en función de lo que invirtamos) y también **interpretar** el modelo y comprender que medio es el que afecta más a las ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El conjunto de entrenamiento X los atributos 'TV', 'Radio' y 'Newspaper'\n",
    "feature_cols = atts[:3]\n",
    "X = data[feature_cols]\n",
    "# y van a ser las ventas\n",
    "y = data[atts[3]]\n",
    "\n",
    "# Se importa LinearRegression y se entrena con fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos la predicción del primer ejemplo\n",
    "\n",
    "# ejemplo es la primera instancia\n",
    "ejemplo = X.iloc[0]\n",
    "tv = ejemplo[0]\n",
    "radio = ejemplo[1]\n",
    "periodico = ejemplo[2]\n",
    "print(ejemplo)\n",
    "# predicción con el modelo\n",
    "lm.predict([[tv,radio,periodico]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accedemos a los coeficientes de cada uno de los atributos y al término independiente\n",
    "\n",
    "print(\"Término independiente \",lm.intercept_)\n",
    "print(\"Coeficientes\")\n",
    "list(zip(feature_cols, lm.coef_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos nos dice que la inversión que influye más en las ventas es la radio, y vemos que la publicidad en prensa escrita no tiene influencia o es negativa.\n",
    "\n",
    "El significado de los coeficientes es equivalente al de los coeficientes en regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos la interpretación\n",
    "tv*lm.coef_[0]+radio*lm.coef_[1]+periodico*lm.coef_[2]+lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Tarea 3:\n",
    "\n",
    "Crea un conjunto de datos aleatorio (con numpy) de 3 columnas y 100 filas.\n",
    "Crea un array de 1x100 que sea una combinación lineal de las 3 columnas del conjunto anterior\n",
    "ej: y = 2*c1+ 4*c2 -3c3 +5\n",
    "\n",
    "Entrena un modelo de regresión lineal y observa como los coeficientes se ajustan a\n",
    "los datos que has inventado\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------------------\n",
    "# Evaluación de clasificadores y regresores <a id=\"evaluacion\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la evaluación de un modelo hay que entrenar dicho modelo con un conjunto de entrenamiento. Posteriormente, usando un conjunto de test, hay que comparar las predicciones realizadas con el valor real.\n",
    "\n",
    "\n",
    "```Python\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# accuracy significa exactitud (es la tasa de acierto)\n",
    "# esta función devuelve un número entre 0 y 1. \n",
    "# 0 Todas las predicciones erroneas, 1 todas correctas\n",
    "accuracy_score(y_real, y_predicha)\n",
    "```\n",
    "\n",
    "## Formas de hacer la evaluación <a id=\"formas\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "Habitualmente los datos de los que disponemos no son ilimitados, por lo que debemos usar los datos disponibles tanto para entrenar como para evaluar el modelo.\n",
    "\n",
    "### Forma incorrecta, usando el propio conjunto de entrenamiento\n",
    "\n",
    "La forma incorrecta de evaluar un clasificador sería usando el propio conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# El dataset iris\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, si usamos el vecinos más cercanos con  *n_neighbors*=1.\n",
    "\n",
    "Este clasificador recordemos que almacenaba en su interior el conjunto de entrenamiento. \n",
    "\n",
    "Si se predice con los mismos ejemplos que se han usado para entrenar, el vecino más cercano de cada ejemplo será el mismo.\n",
    "\n",
    "Es decir, el ejemplo más cercano de la instancia número 27, será la propia instancia número 27 y así con todas salvo que haya ejemplos duplicados.\n",
    "\n",
    "![Vecinos más cercanos wikipedia](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/279px-KnnClassification.svg.png \"Vecinos más cercanos wikipedia\")\n",
    "**Vecinos más cercanos. Wikipedia **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Entrenamos el modelo con X y obtenemos las predicciones también con X.\n",
    "'''\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "model.fit(X, y)\n",
    "# y_model son las clases predichas por el modelo\n",
    "y_model = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si comparamos las predicciones con las etiquetas reales vemos que coinciden a la perfección. Pero no estamos evaluando el modelo correctamente porque hemos usado para test las mismas instancias que en entrenamiento.\n",
    "\n",
    "Un clasificador sencillo como vecinos más cercanos tendrá un 100% de acierto con esta forma erronea de evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "'''\n",
    "accuracy_score devuelve los valores entre 0 y 1\n",
    "Un valor de 1 es equivalente a un 100% de acierto.\n",
    "'''\n",
    "\n",
    "accuracy_score(y, y_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una forma un poco más correcta: División en entrenamiento y test.\n",
    "\n",
    "Una forma más apropiada es dividir el conjunto de datos en entrenamiento y test.\n",
    "El método **train_test_split** del módulo **sklearn.model_selection** (modulo sklearn.cross_validation en las versiones antiguas) recibe los datos $X$, las etiquetas de las clases $y$, una proporcion (entre 0 y 1) de entrenamiento y una semilla aleatoria.\n",
    "\n",
    "Y devuelve $X$ e $y$ divididos en 2 subconjuntos cada uno, la proporción del conjunto de entrenamiento respecto al total se especifica en **train_size**.\n",
    "\n",
    "Más opciones sobre este método en el material adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# divide los datos. X_train será el 60% de los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0,\n",
    "                                   train_size=0.6) # 0.6, el 60% de los datos para entrenamiento\n",
    "\n",
    "# Entrena el modelo con el 60% de los datos\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evalua el modelo con el 40% restante\n",
    "y_predict = model.predict(X_test)\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando un conjunto de entrenamiento y otro de test tenemos una estimación más realista del acierto de nuestro modelo, pero aún no es lo mejor que podemos hacer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Una desventaja de usar la descomposición en entrenamiento y test es que los datos que hemos usado para entrenar el modelo nunca los usamos para hacer el test y viceversa. Si tenemos pocos datos esto puede ser un problema.\n",
    "\n",
    "Y podriamos estar seleccionando para test un subconjunto que sea especialmente fácil de clasificar o viceversa.\n",
    "\n",
    "Una manera de solucionarlo es la validación cruzada:\n",
    "- Primero se usa una partición para entrenamiento y luego esa misma partición para test.\n",
    "- El rendimiento del clasificador es la media de los rendimientos para cada una de las particiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atención a que por el momento estoy usando el mismo método pero con 0.5 de train_size\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0,\n",
    "                                   train_size=0.5)\n",
    "\n",
    "\n",
    "y2_model = model.fit(X1, y1).predict(X2)\n",
    "y1_model = model.fit(X2, y2).predict(X1)\n",
    "aciertos = accuracy_score(y1, y1_model), accuracy_score(y2, y2_model)\n",
    "\n",
    "# tengo 2 modelos, tengo dos tasas de acierto y hago la media\n",
    "print(aciertos)\n",
    "print(np.array(aciertos).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-folds Cross Validation\n",
    "\n",
    "En la celda anterior se han obtenido dos porcentajes de acierto. Se puede hacer la media entre ellos y se obtiene una mejor estimación del error que solamente con una partición. Esto se llama 2-folds cross validation.\n",
    "\n",
    "Esta misma idea se puede ampliar a más folds (más particiones). Por ejemplo con 4 folds, se usaría el 75% del conjunto de datos como entrenamiento y el 25% restante para test y esto mismo se repetiría 4 veces siendo el fragmento de test cada vez un fragmento diferente.\n",
    "\n",
    "![Wikipedia. Validación Cruzada](https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Esquema_castell%C3%A0.jpg/800px-Esquema_castell%C3%A0.jpg)\n",
    "** Wikipedia. Validación cruzada con 4 folds**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Sklearn para hacer los visto en la figura se usa la función **cross_val_score**\n",
    "\n",
    "Ejemplo con 4 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# model recordemos que sigue siendo el algoritmo de Vecinos más cercanos\n",
    "scores = cross_val_score(model, X, y, cv=4)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrando el accuracy (tasa de acierto) medio y su desviación\n",
    "# Usando formateo de texto\n",
    "print(\"Acierto: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "# Sin usar formateo de texto\n",
    "print(\"Acierto: \",scores.mean(), \"(+/- \",scores.std() * 2,\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified k-fold\n",
    "\n",
    "**StratifiedKFold** es una variante de k-fold en donde en cada partición se tiene aproximadamente la misma proporción de instancias de cada clase que la proporción que teniamos en el conjunto completo.\n",
    "\n",
    "Ejemplos de validación cruzada estratificada, con un dataset de 15 ejemplos en dos clases desequilibradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo tenemos que hay más ejemplos de la clase 1 que de la clase 0, con la **StratifiedKFold** esa proporción entre clases se refleja tanto en el entrenamiento como en el test en todas las particiones.\n",
    "De otra manera el particionamiento sería aleatorio y no se tendrian porque mantener las proporciones.\n",
    "\n",
    "Este particionamiento es apropiado en conjuntos de datos desquilibrado, en los que tenemos muchos más ejemplos de una clase que de otra. Con el modo aleatorio, en alguna partición podría haber muy pocos ejemplos en entrenamiento o test y la precicción podría no ser realista (ej solo hay uno en test y lo acierta 100% de acierto)\n",
    "\n",
    "Por defecto el método **cross_val_score** hace partición $k$ fold estratificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "labels = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "y_array = np.array(labels)\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train, test in skf.split(labels, y_array):\n",
    "    print(\"Indices %s %s\" % (train, test))\n",
    "    print(\"valores %s %s\" % (y_array[train], y_array[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Si no hacemos la cross-validación estratificada vemos que \n",
    "en algunas particiones a lo mejor la clase minoritaria no aparece\n",
    "en la parte de entrenamiento o de test.\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "labels = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "y_array = np.array(labels)\n",
    "kf = KFold(n_splits=3)\n",
    "for train, test in kf.split(labels, y_array):\n",
    "    print(\"Indices %s %s\" % (train, test))\n",
    "    print(\"valores %s %s\" % (y_array[train], y_array[test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más formas de particionar los datos para hacer la evaluación en el material adicional.\n",
    "\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Obteniendo predicciones en lugar de scores\n",
    "\n",
    "Con la función **cross_val_score** obtenemos una serie de medidas de precisión obtenidas mediante validación cruzada, pero de manera equivalente podemos obtener las predicciones de cada elemento.\n",
    "\n",
    "La función **cross_val_predict** devuelve la predicción de cada una de las instancias usadas para test, usando validación cruzada.\n",
    "\n",
    "Podemos pensar que esto no sirve para nada, dado que podemos obtener el porcentaje de acierto directamente, pero luego veremos que puede servir para sacar informes y matrices de confusión.\n",
    "\n",
    "También, si queremos obtener muchas medidas diferentes, podemos hacerlo simplemente obteniendo las predicciones y usando estas predicciones para calcular tantas medidas como se quiera (Más adelante cuando veamos que hay más medidas de evaluación hay un ejemplo). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "predicted = cross_val_predict(model, X, y, cv=5)\n",
    "print(\"Predicciones de cada instancia \",predicted)\n",
    "\n",
    "'''\n",
    "despues hago con las predicciones lo que quiera \n",
    "como calcular el accuracy\n",
    "'''\n",
    "\n",
    "print(\"accuracy, porcentaje de acierto\")\n",
    "print(metrics.accuracy_score(y, predicted) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medidas de rendimiento <a id=\"medidas\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "Hasta ahora hemos visto que la validación cruzada es la mejor forma de evaluar un clasificador o un regresor. Y que hay una función llamada **cross_val_score** que nos devuelve la evaluación del clasificador.\n",
    "\n",
    "Pero ¿que devuelve? tasa de acierto?, error absoluto?, error relativo?\n",
    "\n",
    "Por defecto la función **cross_val_score** utiliza el método **score()** del modelo que estemos evaluando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "scores = cross_val_score(knn, X, y, cv=4)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que en el caso de knn devuelve el accuracy\n",
    "print(knn.score.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto los clasificadores suelen devolver el *accuracy* o tasa de acierto.\n",
    "\n",
    "Los regresores suelen devolver el coeficiente de determinación, $R^2$. Que se define como:\n",
    "\n",
    "```Python\n",
    "u = ((y_true - y_pred) ** 2).sum() \n",
    "v = ((y_true - y_true.mean()) ** 2).sum()\n",
    "\n",
    "coef_determinacion = (1 - u/v)\n",
    "```\n",
    "\n",
    "Y es un valor de acierto (cuanto mayor mejor, un valor de error sería cuando menor mejor).\n",
    "\n",
    "El mejor valor es el 1. Cuando el modelo devuelve la media de $y$ sin importar los atributos se obtiene un 0. Y valores negativos significa que es incluso peor que predecir la media\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "¿Pero que otras medidas de rendimiento hay?\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas para regresión\n",
    "\n",
    "En el módulo **sklearn.metrics** se implementa muchas funciones para medir el rendimiento de un regresor. Algunas de esas medidas son:\n",
    "- r2_score. Coeficiente de determinación.\n",
    "- mean_squared_error. Error cuadrático medio. \n",
    "- mean_absolute_error. Error absoluto medio.\n",
    "- explained_variance_score. Varianza explicada por el modelo / total varianza. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "'''\n",
    "Ejemplo.\n",
    "\n",
    "Haciendo regresión lineal y evaluando dos medidas distintas.\n",
    "\n",
    "'''\n",
    "data = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)\n",
    "atts = data.columns\n",
    "\n",
    "feature_cols = atts[:3]\n",
    "X = data[feature_cols]\n",
    "y = data[atts[3]]\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "scores = cross_val_score(lr, X, y, cv=4)\n",
    "print(scores)\n",
    "\n",
    "scores = cross_val_score(lr, X, y, cv=4, scoring = \"mean_absolute_error\")\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas para clasificación \n",
    "\n",
    "El módulo **sklearn.metrics** implementa múltiples medidas del rendimiento de un algoritmo de clasificación.\n",
    "\n",
    "Algunas de las medidas requieren para ser calculadas que el clasificador devuelva probabilidades para cada clase, no solo cual es la clase más probable. Algunas medidas son solo para conjuntos de datos de dos clases etc.\n",
    "\n",
    "Solo vamos a ver las medidas más básicas. El resto quedará en el material adicional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Obtención de la tasa de acierto.\n",
    "Que es la medida por defecto.\n",
    "'''\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(knn1, X, y, cv=4, scoring = \"accuracy\")\n",
    "print(\"Accuracy KNN\", scores)\n",
    "scores = cross_val_score(lr, X, y, cv=4, scoring = \"accuracy\")\n",
    "print(\"Accuracy Regresión Logística\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusión\n",
    "\n",
    "La matriz de confusión es una herramienta para visualizar el desempeño de un algoritmo de aprendizaje supervisado.\n",
    "\n",
    "Es una matriz cuadrada, con tantas filas y columnas como clases diferentes.\n",
    "\n",
    "En las columnas se representan las predicciones de cada clase y en las filas se representan las clases reales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# Se divide el conjunto de datos en entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "classifier = svm.SVC(kernel='linear', C=0.01)\n",
    "\n",
    "\n",
    "# Se entrena un clasificador (SVM) con la parte de entrenamiento \n",
    "# Se predicen las clases con la parte de test\n",
    "y_pred = classifier.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# obtención de la matriz de confusión\n",
    "# filas -> reales\n",
    "# columnas -> predicciones\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los beneficios de las matrices de confusión es que facilitan ver si el sistema está confundiendo dos clases.\n",
    "\n",
    "Se puede ver, más abajo, que 6 versicolores se han clasificado erroneamente como virgínica.\n",
    "\n",
    "(La Fila es la real, la columa la predicción)\n",
    "_____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "El mismo ejemplo, pero convirtiendo la matrix de confusión en un dataFrame para \n",
    "poder visualizar filas y columnas más claramente\n",
    "'''\n",
    "\n",
    "conf_mat_df = pd.DataFrame(cnf_matrix,\n",
    "                           index=class_names,\n",
    "                           columns=class_names)\n",
    "conf_mat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de usando Pandas, se puede visualizar una matriz de confusión muy fácilmente usando Seaborn.\n",
    "\n",
    "Si no tienes seaborn\n",
    "\n",
    "**conda install -c anaconda seaborn **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "\n",
    "ax = sns.heatmap(conf_mat_df, square=True, annot=True, cbar=False)\n",
    "ax.set_xlabel('Predicción')\n",
    "ax.set_ylabel('Real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "Todo lo mencionado anteriormente sobre obtener la tasa de acierto sobre el propio conjunto de datos, un conjunto adicional o mediante validación cruzada sigue siendo aplicable ahora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "La anterior matriz de confusión se ha obtenido con las predicciones obtenidas a partir de los datos de test, que solo eran una parte del conjunto de datos.\n",
    "\n",
    "Para obtener la matriz de confusión usando validación cruzada, se puede usar **cross_val_predict**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtienen predicciones mediante validación cruzada 5 folds\n",
    "predicted = cross_val_predict(classifier, X, y, cv=5)\n",
    "\n",
    "# Se obtiene la matriz de confusión a partir de las predicciones y los valores reales\n",
    "cnf_matrix = confusion_matrix(y, predicted)\n",
    "\n",
    "conf_mat_df = pd.DataFrame(cnf_matrix,\n",
    "                           index=class_names,\n",
    "                           columns=class_names)\n",
    "\n",
    "# Descomenta si tienes seaborn\n",
    "'''\n",
    "ax = sns.heatmap(conf_mat_df, \n",
    "                 square=True, \n",
    "                 annot=True, # muestra los valores\n",
    "                 fmt=\"d\", # las etiquetas como entero\n",
    "                 cbar=True) #muestra el color map\n",
    "ax.set_xlabel('Predicción')\n",
    "ax.set_ylabel('Real')\n",
    "'''\n",
    "\n",
    "conf_mat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Consideraciones respecto a conjuntos binarios donde una clase es mucho mayor que la otra\n",
    "\n",
    "Si el conjunto de datos es binario (2 clases) los ejemplos, se dice que pueden pertenecer a la clase positiva o a la negativa.\n",
    "\n",
    "La positiva es la clase de interés, que generalmente es la minoritaria (el email que es SPAM, el enfermo que tiene diabetes ...)\n",
    "\n",
    "se tienen entonces 4 posibilidades:\n",
    "- TP. True Positive. Un ejemplo positivo clasificado como positivo.\n",
    "- TN. True Negative. Un ejemplo negativo clasificado como negativo.\n",
    "- FP. False Positive. Un ejemplo negativo clasificado como positivo.\n",
    "- FN. Fase Negative. Un ejemplo positivo clasificado como negativo.\n",
    "\n",
    "|    |  P |  N |\n",
    "|----|----|----|\n",
    "|  P | TP | FN |\n",
    "|  N | FP | TN | \n",
    "\n",
    "Recuerda: Filas valores reales. Columnas predicción del clasificador\n",
    "\n",
    "\n",
    "La matriz de confusión puede ser útil cuando el conjunto de datos con el que trabajamos tiene distintas proporciones entre las clases. \n",
    "\n",
    "Si por ejemplo hay 990 muestras de la clase negativa y sólo 10 de la clase positiva, un clasificador que siempre prediga la clase negativa tendrá un porcentaje de acierto del 99%. Pero esto no significa que sea un buen clasificador, pues tuvo un 100% de error en la clasificación de las muestras de la clase positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "X_des, y_des = datasets.make_classification(n_samples=1000, n_features=20,\n",
    "                                    n_informative=2, n_redundant=2,\n",
    "                                    weights = [0.99,0.01],\n",
    "                                    random_state = 27)\n",
    "\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(),  X_des, y_des, cv=5, scoring = \"accuracy\")\n",
    "print(scores.mean()*100,\"% de acierto, está muy bien\")\n",
    "\n",
    "predicted = cross_val_predict(LogisticRegression(), X_des, y_des, cv=5)\n",
    "cnf_matrix = confusion_matrix(y_des, predicted)\n",
    "\n",
    "# Descomenta si tienes seaborn\n",
    "'''\n",
    "ax = sns.heatmap(cnf_matrix, \n",
    "                 square=True, \n",
    "                 annot=True, # muestra los valores\n",
    "                 fmt=\"d\", # las etiquetas como entero\n",
    "                 cbar=True) #muestra el color map\n",
    "ax.set_xlabel('Predicción')\n",
    "ax.set_ylabel('Real')\n",
    "'''\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = cross_val_score(KNeighborsClassifier(),  X_des, y_des, cv=5, scoring = \"accuracy\")\n",
    "print(scores.mean()*100,\"% de acierto, puede parecer que no está tan mal\")\n",
    "\n",
    "print(\"Pero resulta que falla todas las predicciones sobre la clase minoritaria\")\n",
    "\n",
    "predicted = cross_val_predict(KNeighborsClassifier(), X_des, y_des, cv=5)\n",
    "cnf_matrix = confusion_matrix(y_des, predicted)\n",
    "\n",
    "# Descomenta si tienes seaborn\n",
    "'''\n",
    "ax = sns.heatmap(cnf_matrix, \n",
    "                 square=True, \n",
    "                 annot=True, # muestra los valores\n",
    "                 fmt=\"d\", # las etiquetas como entero\n",
    "                 cbar=True) #muestra el color map\n",
    "ax.set_xlabel('Predicción')\n",
    "ax.set_ylabel('Real')\n",
    "'''\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo el clasificador ha acertado más de un 98%, que a priorí es muy bueno.\n",
    "\n",
    "Sin embargo considerando solo la clase minoritaria los resultados son pésimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para trabajar sobre este tipo de conjuntos de datos se han definido nuevas medidas.\n",
    "\n",
    "- Accuracy = $\\frac{TP+TN}{FP+FN+TP+TN}$ o simplemente $\\frac{\\text{aciertos}}{\\text{total}}$.  Tasa de aciertos sin importar de que clase son los fallos.\n",
    "    \n",
    "- Recall = $\\frac{TP}{TP+FN}$. Cuantos de los positivos se han predicho correctamente del total de positivos que había.\n",
    "    \n",
    "- Precision = $\\frac{TP}{TP+FP}$. Cuantos de los positivos se han predicho correctamente del total de predicciones positivas realizadas.\n",
    "    \n",
    "- F-Measure (F1) = $2 \\times \\frac{Recall \\times Precision}{Recall + Precision}$\n",
    "\n",
    "\n",
    "En resumen, al trabajar con conjuntos de datos binarios donde una clase es mayor que la otra hay 2 tipos de errores importantes, los $FP$ y los $FN$.\n",
    "\n",
    "- Recall alto: Se predicen como positivos casi todos los positivos existentes. Hay muy pocos falsos negativos (ejemplos positivos que se hayan clasificado como negativos.)\n",
    "\n",
    "- Precision alto: Se predicen como positivos casi todos los positivos existentes. Hay muy pocos falsos positivos (ejemplos negativos que se hayan clasificado como positivos.)\n",
    "\n",
    "Por ejemplo, en un test que detecta un cáncer queremos un **recall alto**, no queremos que se escape ningún caso positivo, posteriormente se podrán hacer más test y descartar falsos positivos.\n",
    "\n",
    "En un buscador o similar queremos una **precisión alta**, no pasa nada si no recuperamos todos los ejemplo, pero no queremos devolver resultados que no se corresponde con la consulta realizada.\n",
    "\n",
    "\n",
    "Más sobre esto es el material adicional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report\n",
    "\n",
    "La función **classification_report** devuelve un informe en modo texto con las medidas de clasificación más importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=class_names)\n",
    "report.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obteniendo varias medidas a la vez.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo se muestra como si queremos obtener varias medidas en el mismo experimento lo mejor es obtener las predicciones (con **cross_val_predict**) y calcular las medidas a partir de las predicciones. Se hace la validación cruzada 1 vez.\n",
    "\n",
    "Si usamos **cross_val_score** se repite el entrenamiento y el testeo cada vez. Para obtener 4 medidas necesitaríamos hacemos la validación cruzada 4 veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "target_names = data.target_names\n",
    "\n",
    "classifier = svm.SVC(probability=True, random_state=0)\n",
    "predicted = cross_val_predict(classifier, X, y, cv=5)\n",
    "\n",
    "'''\n",
    " ahora con 'y' y 'predicted' se pueden calcular varias \n",
    " medidas  diferentes\n",
    " \n",
    " \n",
    " En el ejemplo cada medida se calcula de las dos maneras, para ver que el resultado es el mismo\n",
    " Pero la segunda forma es más rápida\n",
    "'''\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy\")\n",
    "print(\"%0.3f\"%cross_val_score(classifier, X, y, cv=5).mean() )\n",
    "print(\"%0.3f\"%metrics.accuracy_score(y, predicted))\n",
    "\n",
    "#f1\n",
    "print(\"F1\")    \n",
    "print(\"%0.3f\"%cross_val_score(classifier, X, y, cv=5, scoring='f1').mean())\n",
    "print(\"%0.3f\"%metrics.f1_score(y, predicted))\n",
    "\n",
    "# precision\n",
    "print(\"Precisión\")\n",
    "print(\"%0.3f\"%cross_val_score(classifier, X, y, cv=5, scoring='precision').mean() )\n",
    "print(\"%0.3f\"%metrics.precision_score(y, predicted))\n",
    "\n",
    "# recall\n",
    "print(\"Recall\")\n",
    "print(\"%0.3f\"%cross_val_score(classifier, X, y, cv=5, scoring='recall').mean() )\n",
    "print(\"%0.3f\"%metrics.recall_score(y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "state": {
    "122b8ecea3e642e9af99fd297e1ceeee": {
     "views": [
      {
       "cell_index": 88
      }
     ]
    },
    "419c7d61d63f47109b90ea3ccd7b589e": {
     "views": [
      {
       "cell_index": 60
      }
     ]
    },
    "61c3d843122b41cc89acc729dd6a88b2": {
     "views": [
      {
       "cell_index": 49
      }
     ]
    },
    "ca99a3fd13d241c0b0ec1991fd195f86": {
     "views": [
      {
       "cell_index": 68
      }
     ]
    },
    "f756b60dc4714f368e8a09b1d3fda374": {
     "views": [
      {
       "cell_index": 56
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
