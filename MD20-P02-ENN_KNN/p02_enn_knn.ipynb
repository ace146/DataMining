{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img style=\"float: left;\" width=\"20%\" src=\"pics/escudo_ubu.png\">\n",
    "<br style=\"clear: both;\" />\n",
    "\n",
    "# Minería de datos\n",
    "\n",
    "<h2 style=\"display: inline-block; padding: 4mm; padding-left: 2em; background-color: navy; line-height: 1.3em; color: white; border-radius: 5px;\">Práctica 2: ENN y KNN</h2>\n",
    "\n",
    "## Docentes\n",
    "\n",
    "- Mario Juez Gil (mariojg@ubu.es)\n",
    "\n",
    "<br />\n",
    "**Materiales realizados por:** Mario Juez Gil y José Francisco Diez Pastor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"index\"></a>\n",
    "## Tabla de contenidos del notebook\n",
    "\n",
    "1. [Introducción al aprendizaje supervisado](#intro)\n",
    "2. [Vecinos más cercanos o k-NN](#vecinos)\n",
    "3. [Selección de instancias](#instance-selection)\n",
    "4. [Tareas de la practica k-NN](#tareas)\n",
    "3. [Condiciones de entrega](#entrega)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción al aprendizaje supervisado <a id=\"intro\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "\n",
    "Los algoritmos de aprendizaje supervisado generan un **modelo predictivo** a partir de los datos de entrada y de la salida esperada (la salida también se llama clase). La palabra **supervisado** viene de que un humano debe de haber creado o supervisado los valores de salida que el algoritmo tiene que aprender.\n",
    "\n",
    "El conjunto de datos se denomina conjunto de entrenamiento y se utiliza para que el algoritmo de aprendizaje ajuste sus parámetros (por ejemplo los pesos y el umbral en el caso de las redes neuronales) y permita clasificar correctamente la salida a partir de los datos de entrada.\n",
    "\n",
    "Existen dos tipos de algoritmos de aprendizaje supervisado:\n",
    "- Algoritmos de clasificación: La salida o clase es un valor discreto. **El conjunto de datos \"banana\" que vamos a utilizar, es de clasificación.**\n",
    "- Algoritmos de regresión: La salida o clase es un valor numérico. \n",
    "\n",
    "Estos conceptos y muchos más se ven en la parte teórica de la asignatura, así que los vamos a ver solo de pasada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "En la siguiente celda podemos ver el esquema general de un algoritmo de aprendizaje supervisado y un ejemplo.\n",
    "\n",
    "![esquema general](pics/esquemaGeneral-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vecinos más cercanos o k-NN <a id=\"vecinos\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "- Es el algoritmo de clasificación y regresión más simple.\n",
    "- En la fase de entrenamiento simplemente almacena el conjunto de datos. Puede almacenarlo normalizado, luego veremos que es esto.\n",
    "- Busca los $k$ vecinos más cercanos del ejemplo a predecir ($k$ es un parámetro, por ejemplo con $k=3$ significa que se usan los 3 ejemplos/filas más similares de entre los existentes en el conjunto de entrenamiento). \n",
    "- Pasos:\n",
    "    - Se normalizan los atributos numericos. Restando el mínimo y dividiendo entre el rango.\n",
    "    - Se calcula la distancia entre cada ejemplo, sumando las distancias de cada atributo. \n",
    "    - En atributos nominales (aquellos que no son números sino categorías), la distancia es 0 si son iguales o 1 si son distintos.\n",
    "    - En numéricos es la diferencia de valores.\n",
    "    - Se eligen los $k$ vecinos más cercanos. \n",
    "    - Se predice la moda (clasificación) o la media (regresión) de las clases de los ejemplos más cercanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea general del funcionamiento de vecinos más cercanos.\n",
    "\n",
    "![knn](pics/knnk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la figura podemos ver las áreas de influencia o fronteras de decisión.\n",
    "\n",
    "Todas las regiones de color morado indican que el algoritmo entrenado prediciría la clase \"morado\" para un ejemplo de test localizado en esa casilla.\n",
    "\n",
    "Nota: Los ejemplos de test, son los que se usan para evaluar como de bien funciona un algoritmo de clasificación o regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de instancias <a id=\"instance-selection\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "En la fase de preprocesado de los datos, una estrategia que puede repercutir positivamente en el rendimiento de los modelos de aprendizaje, es la **selección de instancias**.\n",
    "\n",
    "La idea de la selección de instancias es mantener los ejemplos más útiles para el proceso de aprendizaje, y descartar aquellos que carezcan de utilidad e incluso puedan influir de forma negativa.\n",
    "\n",
    "![enn](pics/enn.png)\n",
    "\n",
    "## ENN (Vecinos más cercanos editados)\n",
    "\n",
    "El algoritmo conocido como ENN hace un filtrado de instancias (ejemplos) teniendo en cuenta la idea de vecinos más cercanos.\n",
    "\n",
    "- Dado un ejemplo, se buscan sus $k$ vecinos más cercanos.\n",
    "- Si la clase del ejemplo no se corresponde con la clase mayoritaria de sus $k$ vecinos, ese ejemplo se suprime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tareas de la practica <a id=\"tareas\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "En esta práctica se va a crear una clase llamada \"EKNN\" donde se deben implementar 4 métodos:\n",
    "- vecinos(x,X,y).\n",
    "- filtradoENN(X,y).\n",
    "- entrenar(X,y). \n",
    "- predecir(X).\n",
    "\n",
    "----------\n",
    "\n",
    "- $x$ son los valores de atributos que definen a un ejemplo o individuo\n",
    "- $X$ es un conjunto de ejemplos o individuos, cada uno de los cuales viene definido por los valores de sus atributos.\n",
    "- $y$ son los valores que tratamos de predecir. Son la clase del invididuo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.431573</td>\n",
       "      <td>0.592162</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.421647</td>\n",
       "      <td>0.330900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.707009</td>\n",
       "      <td>0.443339</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.648684</td>\n",
       "      <td>0.810578</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.264226</td>\n",
       "      <td>0.211079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      attr1     attr2  clase\n",
       "0  0.431573  0.592162     -1\n",
       "1  0.421647  0.330900      1\n",
       "2  0.707009  0.443339     -1\n",
       "3  0.648684  0.810578     -1\n",
       "4  0.264226  0.211079      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv('datasets/banana.csv')\n",
    "\n",
    "# head saca los 5 primeros valores.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada ejemplo del conjunto de datos **\"banana\"** está formado por dos atributos (**att1**, y **att2**).\n",
    "\n",
    "La clase a predecir puede tomar **dos** posibles valores (problema de clasificación binaria): **{-1, 1}**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y son los valores de la columna clase\n",
    "# X son todas las columnas menos clase\n",
    "y = df[\"clase\"].values\n",
    "X = df.drop(\"clase\",axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, -1,  1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.431573, 0.592162],\n",
       "       [0.421647, 0.3309  ],\n",
       "       [0.707009, 0.443339],\n",
       "       [0.648684, 0.810578],\n",
       "       [0.264226, 0.211079]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5 primeras filas\n",
    "display(y[:5])\n",
    "display(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos $X$ e $y$ en dos partes. Una parte se usará para entrenar el algoritmo y otra para probar que tal funciona.\n",
    "\n",
    "A la parte que se usa para entrenar el algoritmo se le suele denominar *train* o conjunto de entrenamiento y a la parte que se usa para probar como de bien o mal funciona se le denomina *test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (927, 2)\n",
      "X_test:  (398, 2)\n",
      "y_train:  (927,)\n",
      "y_test:  (398,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "'''\n",
    "Se usa una función de Sklearn que también veremos más adelante en el temario\n",
    "\n",
    "El par X_train, y_train son los atributos y clases del conjunto de entrenamiento (70% de los ejemplos)\n",
    "El par X_test, y_test son los atributos y clases del conjunto de test (30% de los ejemplos)\n",
    "\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7)\n",
    "print(\"X_train: \", np.shape(X_train))\n",
    "print(\"X_test: \", np.shape(X_test))\n",
    "print(\"y_train: \", np.shape(y_train))\n",
    "print(\"y_test: \", np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esqueleto de la clase y el código que se pide\n",
    "\n",
    "\n",
    "A continuación el esqueleto de lo que se pide. El alumno usar el código posterior como referencia y completarlo más abajo en una celda de tipo código.\n",
    "\n",
    "\n",
    "```Python\n",
    "class EKNN:\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def aprenderEstadisticas(self, X):\n",
    "        self.minimo = X.min(axis=0)\n",
    "        self.maximo = X.max(axis=0)\n",
    "        \n",
    "    def normalizar(self, X):\n",
    "        try:\n",
    "            return (X-self.minimo)/(self.maximo-self.minimo)\n",
    "        except AttributeError:\n",
    "            print(\"Aun no se ha calculado el mínimo y el máximo del conjunto de entrenamiento!\")\n",
    "            raise\n",
    "        \n",
    "    def vecinos(self, x, X, y):\n",
    "        #completa este método\n",
    "        pass\n",
    "    \n",
    "    def filtradoENN(self, X, y):\n",
    "        #completa este método\n",
    "        pass\n",
    "    \n",
    "    def entrenar(self,X,y):\n",
    "        # completa este método\n",
    "        pass\n",
    "    \n",
    "    def predecir(self,X):        \n",
    "        valores_predichos = None\n",
    "        X_norm = self.normalizar(X)\n",
    "        # completa este método\n",
    "        # valores_predichos debe de ser un array con las predicciones de cada uno de los ejemplos de X\n",
    "        \n",
    "        return valores_predichos\n",
    "    \n",
    "    \n",
    "# Crea knn con 3 vecinos    \n",
    "eknn = EKNN(3)\n",
    "# entrena con el conjunto de entrenamiento\n",
    "eknn.entrenar(X_train,y_train)    \n",
    "# lo prueba con el conjunto de test\n",
    "predicciones = eknn.predecir(X_test)\n",
    "\n",
    "# calcula la precisión\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predicciones)\n",
    "\n",
    "```\n",
    "\n",
    "Los métodos deberian tener control de errores. Por ejemplo si se usa *predecir* antes de haber invocado *entrenar* debería sacar un mensaje de error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pistas\n",
    "\n",
    "En el método de **vecinos** habría que:\n",
    "- Obtener un array de distancias de $x$ a cada ejemplo de $X$.\n",
    "    - La distancia se calcula sumando las diferencias en valor absoluto a cada uno de los atributos.\n",
    "- Encontrar y retornar los $k$ ejemplos (índices) con distancias menores usando **argsort**.\n",
    "\n",
    "En el método de **filtradoENN** habría que:\n",
    "- Crear unos atributos en la clase $X$ e $y$ e inicializarlos con todos los ejemplos de entrenamiento.\n",
    "- Recorrer todos los ejemplos de los nuevos atributos, y decidir si deben ser suprimidos o no.\n",
    "- Hay que seguir una estrategia decremental, es decir, el array de ejemplos va disminuyendo a medida que filtramos.\n",
    "\n",
    "En el método de **entrenar** habría que:\n",
    "- Calcular el mínimo y el máximo del conjunto de entrenamiento (`aprenderEstadisticas`)\n",
    "- Normalizar X_train a partir del mínimo y máximo calculados (`normalizar`)\n",
    "- Filtrar X_train implementando `filtradoENN`.\n",
    "\n",
    "\n",
    "En el método de **predecir**:\n",
    "- Normalizar los ejemplos a predecir (X\\_test). Usando los máximos y mínimos obtenidos en entrenar (`normalizar`).\n",
    "- Obtener un array de distancias de cada ejemplo de X normalizado a cada ejemplo de X\\_test.\n",
    "    - La distancia se calcula sumando las diferencias en valor absoluto a cada uno de los atributos.\n",
    "- Encontrar los $k$ ejemplos con distancias menores usando **argsort**\n",
    "- Devolver la media de valores $y$ para esos ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (398, 2)\n",
      "X: (927, 2)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-5083d373cef0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[0meknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentrenar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;31m# lo prueba con el conjunto de test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m \u001b[0mpredicciones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredecir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# calcula la precisión\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-5083d373cef0>\u001b[0m in \u001b[0;36mpredecir\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;31m#calculate distanc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mneighboors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvecinos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"neigh:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneighboors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mvalores_predichos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-5083d373cef0>\u001b[0m in \u001b[0;36mvecinos\u001b[1;34m(self, x, X)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mdistSort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mneighbors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistSort\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "class EKNN:\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.minimo = 0\n",
    "        self.maximo = 0\n",
    "        self.normalized = 0\n",
    "        self.trained = False\n",
    "\n",
    "    def aprenderEstadisticas(self, X):\n",
    "        self.minimo = X.min(axis=0)\n",
    "        self.maximo = X.max(axis=0)\n",
    "\n",
    "    def normalizar(self, X):\n",
    "        try:\n",
    "            return (X-self.minimo)/(self.maximo-self.minimo)\n",
    "        except AttributeError:\n",
    "            print(\"Aun no se ha calculado el mínimo y el máximo del conjunto de entrenamiento!\")\n",
    "            raise\n",
    "\n",
    "    \n",
    "    def vecinos(self, x, X):\n",
    "        distances = []\n",
    "        neighbors = list()\n",
    "        dist = 0\n",
    "        print(\"x:\", np.shape(x))\n",
    "        print(\"X:\", np.shape(X))\n",
    "        for i in range(len(x)):\n",
    "            dist += abs(X[i]-x[i])\n",
    "            distances.append((X[i], dist))\n",
    "            distSort = np.argsort(distances[i])[:self.k]\n",
    "        for k in range(self.k):\n",
    "            neighbors.append(distSort[k][0])\n",
    "        return neighbors\n",
    "\n",
    "    def filtradoENN(self, X, y):\n",
    "        #completa este método\n",
    "        pass\n",
    "\n",
    "    def entrenar(self,X,y):\n",
    "        self.aprenderEstadisticas(X)\n",
    "        self.normalized = self.normalizar(X)\n",
    "        self.y = y\n",
    "        self.trained = True\n",
    "\n",
    "    def predecir(self,X):        \n",
    "        valores_predichos = None\n",
    "        X_norm = self.normalizar(X)\n",
    "        distances = []\n",
    "        # completa este método\n",
    "        # valores_predichos debe de ser un array con las predicciones de cada uno de los ejemplos de X\n",
    "        if (not self.trained):\n",
    "            print(\"train first!\")\n",
    "            return None\n",
    "        if (self.k >= len(self.normalized)):\n",
    "            print(\"k >= len(x_train) choose smaller k\")\n",
    "            return None\n",
    "        \n",
    "        #check arguments Datatype\n",
    "        datatype = None\n",
    "        if (isinstance(X_norm, pd.core.frame.DataFrame)):\n",
    "            datatype = \"panda\"\n",
    "        elif (isinstance(X_norm, np.ndarray)):\n",
    "            datatype = \"array\"\n",
    "        else:\n",
    "            print(\"wrong datatype\")\n",
    "            return None\n",
    "        \n",
    "        #calculate distanc\n",
    "        neighboors = self.vecinos(X_norm, self.normalized)\n",
    "        print(\"neigh:\", neighboors)\n",
    "        valores_predichos = np.zeros(len(X))\n",
    "        for i in range(len(X)):\n",
    "            for j in range(self.k):\n",
    "                valores_predichos[i] += self.y[neighboors[j]] \n",
    "            valores_predichos[i] = valores_predichos[i]/self.k\n",
    "        return valores_predichos\n",
    "    \n",
    "\n",
    "# Crea knn con 3 vecinos\n",
    "eknn = EKNN(3)\n",
    "# entrena con el conjunto de entrenamiento\n",
    "eknn.entrenar(X_train,y_train)    \n",
    "# lo prueba con el conjunto de test\n",
    "predicciones = eknn.predecir(X_test)\n",
    "\n",
    "# calcula la precisión\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7713567839195979"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EKNN:\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.minimum = 0\n",
    "        self.maximum = 0\n",
    "        self.normalised = 0\n",
    "        self.trained = False\n",
    "\n",
    "    def aprenderEstadisticas(self, X):\n",
    "        self.minimo = X.min(axis=0)\n",
    "        self.maximo = X.max(axis=0)\n",
    "\n",
    "    def normalizar(self, X):\n",
    "        try:\n",
    "            return (X-self.minimum)/(self.maximum-self.minimum)\n",
    "        except AttributeError:\n",
    "            print(\"Aun no se ha calculado el mínimo y el máximo del conjunto de entrenamiento!\")\n",
    "            raise\n",
    "\n",
    "    def vecinos(self, x, X, y):\n",
    "        #completa este método\n",
    "        distances = []\n",
    "        length_X = self.normalizar(X)\n",
    "        length_x = self.normalizar(x)\n",
    "        for i in range(length_X):\n",
    "            distances.append([])\n",
    "            for j in range(length_x):\n",
    "                distances[i].append(sum(abs(x[i]-X[j])))\n",
    "        return np.argsort(distances)[:self.k]\n",
    "            \n",
    "\n",
    "    def filtradoENN(self, X, y):\n",
    "        #completa este método\n",
    "        self.y = y_train\n",
    "        self.X = X_train\n",
    "\n",
    "    def entrenar(self,X,y):\n",
    "        # completa este método\n",
    "        self.minimum = X.min(axis=0)\n",
    "        self.maximum = X.max(axis=0)\n",
    "        self.aprenderEstadisticas(X)\n",
    "        self.normalised = self.normalizar(X)\n",
    "        self.y = y\n",
    "        self.trained = True\n",
    "\n",
    "    def predecir(self,X):        \n",
    "        if (not self.trained):\n",
    "            print(\"train first!\")\n",
    "            return None\n",
    "        if (self.k >= len(self.normalised)):\n",
    "            print(\"k >= len(x_train) choose smaller k\")\n",
    "            return None\n",
    "\n",
    "        normalisedX = self.normalizar(X)\n",
    "        distance = []\n",
    "        \n",
    "        #check arguments Datatype\n",
    "        datatype = None\n",
    "        if (isinstance(normalisedX, pd.core.frame.DataFrame)):\n",
    "            datatype = \"panda\"\n",
    "        elif (isinstance(normalisedX, np.ndarray)):\n",
    "            datatype = \"array\"\n",
    "        else:\n",
    "            print(\"wrong datatype\")\n",
    "            return None\n",
    "        \n",
    "        #calculate distance\n",
    "        for i in range(len(normalisedX)):\n",
    "            distance.append([])\n",
    "            for j in range(len(self.normalised)):\n",
    "                if(datatype == \"panda\"):\n",
    "                    distance[i].append(sum(abs(normalisedX.iloc[i]-self.normalised.iloc[j])))\n",
    "                else:\n",
    "                    distance[i].append(sum(abs(normalisedX[i]-self.normalised[j])))\n",
    "        \n",
    "        #calculate predictions\n",
    "        predictedValues = np.zeros(len(X))\n",
    "        for i in range(len(X)):\n",
    "            idx = np.argsort(distance[i])[:self.k]\n",
    "            for j in range(self.k):\n",
    "                predictedValues[i] += self.y[idx[j]] \n",
    "            predictedValues[i] = predictedValues[i]/self.k    \n",
    "        return predictedValues\n",
    "\n",
    "\n",
    "# Crea knn con 3 vecinos    \n",
    "eknn = EKNN(3)\n",
    "# entrena con el conjunto de entrenamiento\n",
    "eknn.entrenar(X_train,y_train)    \n",
    "# lo prueba con el conjunto de test\n",
    "predicciones = eknn.predecir(X_test)\n",
    "# calcula la precisión\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predicciones.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condiciones de entrega <a id=\"entrega\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "\n",
    "- La entrega debe realizarse a través de UBUVirtual antes del **20 de marzo de 2020 a las 23:59**.\n",
    "- Se debe entregar un .zip con este proyecto jupyter notebook con la solución.\n",
    "- Adicionalmente (no es obligatorio, pero se valorará positivamente) se puede hacer un informe comparando la solución obtenida con vuestra implementación, contra la obtenida con un workflow en KNIME donde utilicéis el nodo K Nearest Neighbor, razonando si el uso de la estrategia de selección de instancias afecta positivamente al rendimiento del KNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
